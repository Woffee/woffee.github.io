<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://woffee.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://woffee.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-27T15:46:44+00:00</updated><id>https://woffee.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Sora物理悖谬的几何解释</title><link href="https://woffee.github.io/blog/2024/Sora/" rel="alternate" type="text/html" title="Sora物理悖谬的几何解释"/><published>2024-02-27T13:56:00+00:00</published><updated>2024-02-27T13:56:00+00:00</updated><id>https://woffee.github.io/blog/2024/Sora</id><content type="html" xml:base="https://woffee.github.io/blog/2024/Sora/"><![CDATA[<blockquote> <p>原文转载自：顾险峰 - Sora物理悖谬的几何解释</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sora/p0-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sora/p0-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sora/p0-1400.webp"/> <img src="/assets/img/sora/p0.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image for relax. </div> <p>龙年伊始，Sora横空出世，举世震惊。Sora声称“作为世界模拟的视频生成模型”，豪气干云。有人悲观预言很多传统领域可能被颠覆，其中最为岌岌可危的可能是计算机图形学，短视频和影视娱乐行业。依随OpenAI透露出更多技术细节，很多Sora生成的物理悖谬的视频流传于网络。</p> <p>这里笔者依据现代数学特别是整体微分几何领域的一些观点来解释目前Sora技术路线中的缺陷，希望能够抛砖引玉，为广大AI研究和工程人员拓宽思路，共同促进提高。这里主要用流形嵌入理论、灾变理论（临界态理论）、纤维丛示性类理论、热扩散方程和最优传输方程（蒙日-安培方程）的正则性理论来解释。</p> <h1 id="流形分布定则">流形分布定则</h1> <p>在深度学习领域，一个自然的数据集被视为一个流形上的概率分布，这被称为是流形分布定则。我们将观察到的一个样本看成是原始数据空间中的一个点，大量的样本构成原始数据空间中的一个稠密点云，这片点云在某个低维流形附近，这个流形被称为是数据流形。点云在数据流形上的分布并不均匀，而是满足特定的分布规律，被表示成数据概率分布。</p> <p>那么，我们自然产生如下的疑问：1. 为什么数据点云是低维的，而非占满整个原始数据空间？2. 为什么点云集合是流形，即局部是连续光滑的？</p> <p>关于第一个疑问的回答是：因为自然现象满足大量的自然规律，这些规律的限制降低了数据样本点云的维数，而无法占满整个空间。比如，我们考察所有自然人脸照片构成的数据集，每个采样点是一张图片，像素的个数乘以3就是原始图像空间的维数。原始图像空间中的任意一点，都是一幅图片，但是极少的图片才是人脸图片，才会落在人脸图片流形上，因此人脸图片流形不可能占满整个原始图像空间。</p> <p>人脸需要满足很多自然的生理学规律，每个规律都会降低数据流形的维数，例如左右对称，就减少了近一半的像素，都有五官等确定的几何与纹理区域，每个器官的形状类似，描述的参数不多，因此进一步降低维数。最终控制人脸的基因非常有限，由此人脸图片流形的维数远远低于图片像素个数。</p> <p>再如，我们观察平面区域的稳恒态温度分布，由物理热扩散定理，稳定函数满足经典的Laplace方程，由其边界值所唯一确定。如果我们在区域内部有n平方个采样点，在区域边界有n个采样点，那么每个观察到的温度函数被表示为维数为n平方的向量，即原始数据空间维数为n平方，但是实际的流形维数为边界函数的维数n。由此可见，满足物理定律的观察样本构成的数据流形维数远远低于原始数据空间维数。</p> <p>关于第二个问题的回答是：绝大多数情形下，物理系统是适定的，但在临界状态下，物理系统会发生突变（由灾变理论或者临界态理论来描述）。物理定律多由偏微分方程系统来描述，微分方程的解由初始值和边界值来控制，系统是适定的，意味着由于能量守恒、质量守恒、能量传递小于光速等物理限制，初边值逐渐变化时，解也随之逐渐变化。在偏微分方程的正则性理论中，这意味着边值的索伯列夫范数控制解的索伯列夫范等等。我们将解视为数据流形上的点，边值视为其对应的局部坐标（即隐空间中的对应隐特征向量）。</p> <p>从数据流形到隐空间的映射被称为是编码映射，从隐空间到数据流形的映射被称为是解码映射。正则性理论保证编码映射和解码映射是连续的乃至光滑的，解的唯一性保证这些映射是拓扑同胚或者微分同胚。边值可以任意局部扰动，即隐变量存在一个开欧式圆盘的邻域。这意味着满足特定物理定则的观察样本构成了数据流形。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sora/p1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sora/p1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sora/p1-1400.webp"/> <img src="/assets/img/sora/p1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 图1. Sora 将视频编码映射到隐空间，再切割成时空补丁，被称为时空令牌（time-space token）。(openai.com) </div> <p>如图1. 所示，Sora的训练集为短视频集，每个样本是一个短视频，同类的短视频构成一个数据流形。Sora将其编码到隐空间进行降维，然后在隐空间中将隐特征向量切割成补丁，加上时间顺序，构成时空补丁，亦即时空令牌（time-space token）。这里时空的概念是比较关键的，每个令牌在短视频的帧序列号（时间），在当前帧的行列序号（空间）都被记录在令牌里。</p> <h1 id="概率分布变换">概率分布变换</h1> <p>我们可以进一步问如下问题：3. 数据流形上的概率分布如何表示？</p> <p>关于第三个问题的回答是：用传输变换，将数据概率分布变成计算机可以生成的高斯分布。这个传输变换可以在原始数据空间中进行，也可以在隐空间中进行。常用的传输变换包括最优传输变换和热扩散。我们用流体力学的观点来解释。假设整个隐空间是一个水箱，里面有某种溶剂，其密度为概率密度。我们扰动水箱，使得液体流动起来，使得溶剂密度发生变化。我们计算每个水分子的流向和流速，使得概率密度的熵一直增加，最后就得到高斯分布。</p> <p>例如，我们考虑人脸数据分布，这里每个水分子就是一张人脸图片。我们为人脸图片不断添加噪声，得到一系列图片，直至变成一张白噪声图片。这一系列图片就是水分子的运动轨迹。最后每张人脸图片变成白噪声，所有这些白噪声分布满足高斯分布。这一过程被称为是郎之万的动力学。</p> <p>反过来，给定一张白噪声，我们沿着水分子轨迹倒溯源头，就得到一张人脸图片。这就是扩散生成模型的原理（diffusion model）。当然，也可以直接用最有传输理论求解隐空间到自身的同胚，将数据分布变成高斯分布，这需要求解蒙日-安培方程。由此可见，数据分布的所有信息都由传输映射所包含，而传输映射被一个深度网络来表达。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sora/p2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sora/p2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sora/p2-1400.webp"/> <img src="/assets/img/sora/p2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 图2. Sora用扩散模型从白噪声时空令牌生成数据时空令牌。（openai.com） </div> <p>如图2所示，Sora在隐空间将数据令牌的概率分布通过扩散过程（郎之万动力系统-每个令牌上逐渐添加噪声）传输变换成高斯分布，再通过传输变换的逆变换将隐空间中的白噪声令牌变成隐数据令牌。</p> <h1 id="大语言模型的加持">大语言模型的加持</h1> <p>Sora结合了大语言模型ChatGPT，这极大地提升了系统的性能。首先，Soar的训练样本是（文本，视频）对，有些视频对应的标题过于简短，字幕缺少，Sora采用了Dall-E的重新标题技术。</p> <p>Sora的训练集包含一些优质的样本，（高度描述性字幕，短视频），由此训练了短视频数据流形（包括时空令牌流形），每个流形用其字幕（标题）来标识。对于缺乏标题或者字幕含混的劣质短视频，Sora将其编码到隐空间，在隐空间中寻找临近优质视频的隐特征向量，然后将优质视频的字幕（标题）拷贝给劣质视频。用这种方法，Sora可以为所有的训练视频数据添加高度描述性的字幕，从而提高了训练集的质量，进一步提升系统性能。</p> <p>同时大语言模型可以将用户输入的提示进行扩充，变得更加精准，更加具有描述性，从而使得生成视频与用户需求更好契合。这使得Sora如虎添翼。但是Sora依然存在着很多缺陷，我们可以通过如下例子进行分析。</p> <h1 id="相关性与因果律的矛盾">相关性与因果律的矛盾</h1> <p>ChatGPT将语句分解成令牌，然后用Transformer学习在上下文中令牌间连接的概率分布。与此类似，Sora将视频分解成时空令牌，然后学习上下文中令牌间连接的概率分布，并且依据这一概率分布由白噪声生成令牌，连接令牌，解码成短视频。</p> <p>每个令牌表达图像或者视频中的一个局部区域，不同局部区域间的拼接成为问题的关键。Sora相对独立地学习每个令牌，将令牌间的空间关系用训练集中体现的概率来表达，从而无法精准表达令牌间时空的因果关系。</p> <p>视频1. Sora生成的老奶奶吹生日蜡烛视频。（openai.com）</p> <p>如视频1所示，在Sora生成的视频中，每一帧都异常逼真，但是当老奶奶吹了生日蜡烛的时候，蜡烛的火苗纹丝不动。如果我们将视野缩小到每一个令牌的区域，我们看到美轮美奂的真实画面，令牌之间的衔接也非常平滑自然，但是当相距较远的令牌之间有因果联系的时候，即吹出的空气影响火苗的跳动时，两个令牌之间的物理因果没有体现出来。</p> <p>这意味着Transformer用以表达令牌之间的统计相关性，无法精确表达物理因果律。虽然transformer可以在一定程度上操纵自然语言，但自然语言无法准确表达物理定律，而物理定律目前只有偏微分方程才能精密表达。这反应了基于概率的世界模型的某种局限性。</p> <h1 id="局部合理与整体荒谬的矛盾">局部合理与整体荒谬的矛盾</h1> <p>目前Sora相邻令牌间的拼接做得很合理，但是整体拼接的视频却可能出现各种悖谬。这意味着局部拼接与整体拓展之间的鸿沟。</p> <p>视频2. Sora生成的“幽灵椅子”视频。（openai.com） 我们观察“幽灵椅子”视频，如果我们将视野限制在屏幕中间的一个局部区域，则视频非常合理。仔细检测不同令牌区间直接的连接，也非常连续光滑。但是整个椅子如鬼魅般悬空，这与日常经验相悖。</p> <p>这种“局部合理，整体荒谬”的生成视频，意味着Transformer学会了Token间局部的连接概率，但是缺乏时空上下文的大范围整体观念。在这个视频中，整体观念来自于物理中的重力场，虽然局部看不出来，但是整体上无时不在。</p> <p>视频3. Sora 生成的四足蚂蚁。（openai.com）</p> <p>再如Sora生成的“四足蚂蚁”的视频，蚂蚁的动作栩栩如生，宛如行云流水。局部上非常流畅自然，令人不禁联想或许在某个星球上存在这种四足蚂蚁。但是整体上，地球的自然界并没有四足蚂蚁。这里局部的合理无法保证整体的合理，这里的全局观念来自于生物学的事实。</p> <p>视频4. Sora 生成的南辕北辙跑步机。（openai.com）</p> <p>再如Sora生成的“南辕北辙跑步机”视频，如果我们观察每一个局部区域，看到的视频都是合理的，视频令牌间的连接也是自然的，但是整体视频却是荒谬的，跑步机与跑步者的方向相反。这个视频的全局观与来自于人体工程学的事实相悖。</p> <p>这些例子表明，目前的Transformer虽然可以学习局部的上下文，但无法学习更加全局的上下文，这里的全局可能是物理中的重力场，也可以是人体工程学，或者生物中的物种分类。这种全局观点，恰是朱松纯教授提出的AI世界中的暗物质思想。虽然每个训练样本视频都隐含地表达了全局的观念，但是令牌化的过程却割裂了全局的观念，有限地保留了临近令牌间的连接概率，从而导致局部合理，整体荒谬的结果。</p> <p>现代整体微分几何非常重视整体和局部的矛盾，为此发明了多种理论工具。比如，我们可以在拓扑流形的局部构造光滑标架场，但是无法将其全局推广，全局推广的障碍就是纤维丛的示性类。复流形上，我们可以局部构造亚纯函数，但是整体上无法将局部的函数拼接成整体的亚纯函数，这种局部推广到整体的差异用层的上同调理论来精确刻画。</p> <p>很多物理理论都表示成特定纤维丛的示性类理论，例如拓扑绝缘体理论。这种局部容易构造，整体推广出现实质性困难的数学理论，实际上是人类深层次探索自然的智慧结晶。这种整体的拓扑、几何观点目前还没有推广到AI领域，如果Transformer能够自行学会这种上下文中的整体障碍，那么AI将会更加有效地探索自然界。</p> <h1 id="临界状态的缺失">临界状态的缺失</h1> <p>自然界的绝大多数物理过程都是稳恒态与临界态的交替变化。在稳恒态中，系统参数缓慢变化，容易获取观察数据；在临界态中（灾变态），系统骤然突变，令人猝不及防，很难抓拍到观察数据。因此，临界态的数据样本非常稀少，几乎在训练集中零测度。</p> <p>由此，Sora系统学习到的数据流形，绝大多数都是由稳恒态的样本所构成。物理过程中的临界态样本多分布在数据流形的边界。因此，在生成过程中，Sora非常容易生成稳恒态的视频片段，但是往往跳过临界态。但是在人类认知中，最为关键的观察恰恰是概率几乎为零的临界态。</p> <p>视频5. Sora 生成的果汁泼溅。（openai.com） Sora生成的果汁泼溅视频中，有两个稳定状态，水杯直立的状态，和果汁已经泼溅出来的状态，但是最为关键的临界状态：果汁从杯中流洒出来的过程却没有生成出来。虽然只有短暂的几帧，但是对于人类感知整个过程却是非常重要。Sora无法生成关键临界态的图像可能有如下原因：</p> <p>物理过程中的不同稳衡态样本生成数据流形的不同联通分支，临界态样本在稳恒态流形边界附近，在两个稳衡态流形边界之间。热力学扩散过程将流形的边界变得模糊，从而混淆了流形边界，生成了过程含混的视频。换言之，临近态对应着数据流形的边界，学习过程中应该保持边界情形，而不应产生模式混淆。</p> <p>图3. 模式混淆(mode mixture)。</p> <p>如图3所示，我们用MNIST训练了一个编码解码器，在隐空间画出了数据集的隐空间分布，10个手写体数字对应着10个团簇，每个团簇是一个模式（mode），即数据流形的一个联通分支。团簇的边界就是数据隐空间分布支集的边界。我们在隐空间生成了100个采样点，通过解码生成100个手写体数字图像。如果采样点落在某个团簇内部，则其生成的图像就非常清晰；如果采样点落在团簇边界的外部，则其生成的图像就非常模糊，往往是两个手写体数字的融合。因此，识别数据流形的边界对于识别临界状态非常重要。</p> <p>Sora采用的目前最为热门的扩散模型，在计算传输映射的时候，必然会光滑化数据流形的边界，从而混淆不同的模式，直接跳过临界态图像的生成。因此视频看上去从一个状态突然跳跃到另外一个状态，中间最为关键的倾倒过程缺少，导致物理上的荒谬。</p> <p>视频6. Sora 生成的小狗。（openai.com）</p> <p>视频6显示了另外一种由于横跨流形边界而出错的情形。Sora生成小狗群在嬉笑斗闹，时而相互遮挡，时而散开。在视频的某一刹那，屏幕中的3只小狗突然变成4只小狗。我们如此解释：4只小狗的图片构成一个流形（或者连通分支），3只小狗的图片构成另一个分支，在4只小狗图片流形的边界处，有个临界事件：四只小狗彼此遮挡，图片中只能看到3只小狗。</p> <p>Sora的扩散模型没有识别出流形的边界，而是冲破这边界，在3只小狗图片的流形和4只小狗图片的流形间跨越。正确的做法应该是先识别流形的边界，然后在物理无法跨越的情形下（如3只边4只），在边界处返折回原来流形。</p> <p>图4. 基于几何方法的最优传输映射可以精确检测到数据流形的边界，精确得到临界态。</p> <p>扩散模型的弊端可以被基于几何方法的最优传输模型所克服。如图4所示，假设我们计算从圆盘内部的均匀分布到右侧海马形状区域内的均匀分布的最优传输映射，根据相应的Brenier定理，最优传输映射由某个凸势能函数的梯度映射给出。这一势能函数满足蒙日-安培方程，势能函数并非处处可导，其连续、非可导的集合投影到圆盘区域的奇异集合（黑色曲线），规则点映射到目标区域的规则点，奇异集合映射到目标区域的边界（每个奇异点同时映射到左右两个边界点）。</p> <p>当我们跨越奇异集合的时候，就意味着我们跨越了两个稳衡态，必然有临界（灾变）事件发生，即稳恒态被打破的物理事件。由此可见，精确找到传输映射的奇异集合，探测临界（灾变）状态，对于物理世界建模具有根本的重要性。</p> <h1 id="小结">小结</h1> <p>由此可见，虽然Sora声称是“作为世界模拟的视频生成模型”，目前的技术路线无法正确模拟世界的物理规律。</p> <p>首先，用概率统计的相关性无法精确表达物理定律的因果性，自然语言的上下文相关无法达到偏微分方程的精密程度；其次，虽然Transformer可以学习临近时空令牌间的连接概率，但是无法判断全局的合理性，整体的合理性需要更高层次的数学理论观点、或者更为隐蔽而深厚的自然科学和人文科学的背景，目前的Transformer无法真正悟出这些全局观点；</p> <p>另外，Sora忽略了物理过程中最为关键的临界（灾变）态，一方面因为临界态样本的稀缺，另一方面因为扩散模型将稳恒态数据流形的边界模糊化，消弭了临界态的存在，生成的视频出现了不同稳恒态之间的跳跃。</p> <p>而基于几何方法的最优传输理论框架，可以精确检测到稳恒态数据流形的边界，从而强调了临界态事件的生成，避免了不同稳恒态之间的横跳，更加接近物理的真实。</p> <p>目前，由Sora为代表的数据驱动世界模拟模型，和由第一性原理建立起来的物理定律和偏微分方程的世界模拟模型开始进入了酣战状态。这或许是人类历史的伟大转折点。希望年轻的读者们都能踊跃跻身到时代的洪流之中，用自己的聪明才智推动科技与社会的发展！</p>]]></content><author><name></name></author><category term="PHD"/><category term="DL"/><category term="NLP"/><category term="CV"/><summary type="html"><![CDATA[龙年伊始，Sora横空出世，举世震惊。Sora声称“作为世界模拟的视频生成模型”，豪气干云。有人悲观预言很多传统领域可能被颠覆，其中最为岌岌可危的可能是计算机图形学，短视频和影视娱乐行业。依随OpenAI透露出更多技术细节，很多Sora生成的物理悖谬的视频流传于网络。]]></summary></entry><entry><title type="html">VR/AR Changes Life</title><link href="https://woffee.github.io/blog/2024/VR-AR-Changes-Life/" rel="alternate" type="text/html" title="VR/AR Changes Life"/><published>2024-02-02T12:56:00+00:00</published><updated>2024-02-02T12:56:00+00:00</updated><id>https://woffee.github.io/blog/2024/VR-AR-Changes-Life</id><content type="html" xml:base="https://woffee.github.io/blog/2024/VR-AR-Changes-Life/"><![CDATA[<p>By adding another dimension, virtual reality makes even household chores fun.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://pbs.twimg.com/media/GFV2qU4WUAAmOSX?format=jpg&amp;name=large-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://pbs.twimg.com/media/GFV2qU4WUAAmOSX?format=jpg&amp;name=large-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://pbs.twimg.com/media/GFV2qU4WUAAmOSX?format=jpg&amp;name=large-1400.webp"/> <img src="https://pbs.twimg.com/media/GFV2qU4WUAAmOSX?format=jpg&amp;name=large" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Household chores. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://pbs.twimg.com/media/GFV2rlfXsAACywx?format=jpg&amp;name=large-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://pbs.twimg.com/media/GFV2rlfXsAACywx?format=jpg&amp;name=large-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://pbs.twimg.com/media/GFV2rlfXsAACywx?format=jpg&amp;name=large-1400.webp"/> <img src="https://pbs.twimg.com/media/GFV2rlfXsAACywx?format=jpg&amp;name=large" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Playing piano (1). </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://pbs.twimg.com/media/GFV2pEKX0AA3tGa?format=jpg&amp;name=large-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://pbs.twimg.com/media/GFV2pEKX0AA3tGa?format=jpg&amp;name=large-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://pbs.twimg.com/media/GFV2pEKX0AA3tGa?format=jpg&amp;name=large-1400.webp"/> <img src="https://pbs.twimg.com/media/GFV2pEKX0AA3tGa?format=jpg&amp;name=large" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Playing piano (2). </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://pbs.twimg.com/media/GFV2nYnWYAAW90g?format=jpg&amp;name=medium-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://pbs.twimg.com/media/GFV2nYnWYAAW90g?format=jpg&amp;name=medium-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://pbs.twimg.com/media/GFV2nYnWYAAW90g?format=jpg&amp;name=medium-1400.webp"/> <img src="https://pbs.twimg.com/media/GFV2nYnWYAAW90g?format=jpg&amp;name=medium" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Games. </div>]]></content><author><name></name></author><category term="Life"/><category term="Life"/><summary type="html"><![CDATA[By adding another dimension, virtual reality makes even household chores fun.]]></summary></entry><entry><title type="html">Things that strengthen an IR paper</title><link href="https://woffee.github.io/blog/2024/IR-paper-recommendations/" rel="alternate" type="text/html" title="Things that strengthen an IR paper"/><published>2024-02-02T12:56:00+00:00</published><updated>2024-02-02T12:56:00+00:00</updated><id>https://woffee.github.io/blog/2024/IR-paper-recommendations</id><content type="html" xml:base="https://woffee.github.io/blog/2024/IR-paper-recommendations/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://pbs.twimg.com/media/GEnzBLLWEAE8jJg?format=jpg&amp;name=4096x4096-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://pbs.twimg.com/media/GEnzBLLWEAE8jJg?format=jpg&amp;name=4096x4096-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://pbs.twimg.com/media/GEnzBLLWEAE8jJg?format=jpg&amp;name=4096x4096-1400.webp"/> <img src="https://pbs.twimg.com/media/GEnzBLLWEAE8jJg?format=jpg&amp;name=4096x4096" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image for relax. </div> <h2 id="presentation">Presentation</h2> <ol> <li>The paper’s motivation and the potential impact of the addressed problem are discussed.</li> <li>The paper’s original contributions (i.e. the delta over prior art) are clearly stated.</li> <li>The paper’s claims are properly scoped and supported.</li> <li>The paper clearly describes what was done and what was not.</li> <li>The choices made in each step of the research are justified (the why’s).</li> <li>The results are presented effectively in appropriate format.</li> <li>Good discussion accompanies the results.</li> </ol> <h2 id="experimentation-if-applicable">Experimentation (if applicable)</h2> <ol> <li>The experimental design and its scale are appropriate.</li> <li>In comparative studies, appropriate baselines are used.</li> <li>The experimental results are reliable and generalizable.</li> <li>The evaluation methods employed are in line with the research questions.</li> <li>Statistical analysis is performed and reported appropriately.</li> <li>Sufficient details (with data and code where appropriate) are provided to help other researchers assess and reproduce the experiments.</li> </ol>]]></content><author><name></name></author><category term="PHD"/><category term="PHD"/><summary type="html"><![CDATA[Things that strengthen an IR paper, recommendations from the Program Chairs.]]></summary></entry><entry><title type="html">Using joblib.Memory to cache function results</title><link href="https://woffee.github.io/blog/2023/Memory-Cache/" rel="alternate" type="text/html" title="Using joblib.Memory to cache function results"/><published>2023-10-22T12:56:00+00:00</published><updated>2023-10-22T12:56:00+00:00</updated><id>https://woffee.github.io/blog/2023/Memory-Cache</id><content type="html" xml:base="https://woffee.github.io/blog/2023/Memory-Cache/"><![CDATA[<p>If we need to call our function several time with the same input data, it is beneficial to avoid recomputing the same results over and over since it is expensive. <code class="language-plaintext highlighter-rouge">joblib.Memory</code> enables to cache results from a function into a specific location.</p> <h3 id="example">Example</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">joblib</span> <span class="kn">import</span> <span class="n">Memory</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">location</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./cachedir</span><span class="sh">'</span>
<span class="n">memory</span> <span class="o">=</span> <span class="nc">Memory</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nc">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>


<span class="nd">@memory.cache</span>
<span class="k">def</span> <span class="nf">my_costly_compute_cached</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">column_index</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Simulate an expensive computation</span><span class="sh">"""</span>
    <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">column_index</span><span class="p">]</span>



<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">data_trans</span> <span class="o">=</span> <span class="nf">my_costly_compute_cached</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="s">The function took {:.2f} s to compute.</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="s">The transformed data are:</span><span class="se">\n</span><span class="s"> {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">data_trans</span><span class="p">))</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">data_trans</span> <span class="o">=</span> <span class="nf">my_costly_compute_cached</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="s">The function took {:.2f} s to compute.</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="s">The transformed data are:</span><span class="se">\n</span><span class="s"> {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">data_trans</span><span class="p">))</span>
</code></pre></div></div> <h3 id="outputs">Outputs</h3> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The function took 5.08 s to compute.

The transformed data are:
 [ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696
  1.57921282  0.76743473 -0.46947439  0.54256004]

The function took 0.03 s to compute.

The transformed data are:
 [ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696
  1.57921282  0.76743473 -0.46947439  0.54256004]
</code></pre></div></div> <h3 id="references">References</h3> <ul> <li><a href="https://joblib.readthedocs.io/en/latest/auto_examples/memory_basic_usage.html">https://joblib.readthedocs.io/en/latest/auto_examples/memory_basic_usage.html</a></li> </ul>]]></content><author><name></name></author><category term="PHD"/><category term="Code"/><summary type="html"><![CDATA[This example illustrates the usage of joblib.Memory with functions.]]></summary></entry><entry><title type="html">K-Fold Cross Validation</title><link href="https://woffee.github.io/blog/2023/K-Fold-Cross-Validation/" rel="alternate" type="text/html" title="K-Fold Cross Validation"/><published>2023-08-25T13:56:00+00:00</published><updated>2023-08-25T13:56:00+00:00</updated><id>https://woffee.github.io/blog/2023/K-Fold-Cross-Validation</id><content type="html" xml:base="https://woffee.github.io/blog/2023/K-Fold-Cross-Validation/"><![CDATA[<p>Source: <a href="https://www.analyticsvidhya.com/blog/2022/02/k-fold-cross-validation-technique-and-its-essentials/#h-what-is-k-fold-cross-validation">K-Fold Cross Validation Technique and its Essentials</a></p> <h2 id="what-is-k-fold-cross-validation">What is K-Fold Cross Validation?</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/K-fold-cross-vaslidation-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/K-fold-cross-vaslidation-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/K-fold-cross-vaslidation-1400.webp"/> <img src="/assets/img/K-fold-cross-vaslidation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Life Cycle of K-Fold Cross-Validation. </div> <p>K-fold cross-validation is a technique for evaluating predictive models. The dataset is divided into k subsets or folds. The model is trained and evaluated k times, using a different fold as the validation set each time. Performance metrics from each fold are averaged to estimate the model’s generalization performance. This method aids in model assessment, selection, and hyperparameter tuning, providing a more reliable measure of a model’s effectiveness.</p> <p>In each set (fold) training and the test would be performed precisely once during this entire process. It helps us to avoid overfitting. As we know when a model is trained using all of the data in a single short and give the best performance accuracy. To resist this k-fold cross-validation helps us to build the model is a generalized one.</p> <p>To achieve this K-Fold Cross Validation, we have to split the data set into three sets, Training, Testing, and Validation, with the challenge of the volume of the data.</p> <p>Here Test and Train data set will support building model and hyperparameter assessments.</p> <p>In which the model has been validated multiple times based on the value assigned as a parameter and which is called K and it should be an INTEGER.</p> <p>Make it simple, based on the K value, the data set would be divided, and train/testing will be conducted in a sequence way equal to K time.</p> <h2 id="life-cycle-of-k-fold-cross-validation">Life Cycle of K-Fold Cross-Validation</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/K-fold-cross-vaslidation2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/K-fold-cross-vaslidation2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/K-fold-cross-vaslidation2-1400.webp"/> <img src="/assets/img/K-fold-cross-vaslidation2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Life Cycle of K-Fold Cross-Validation. </div> <p>Let’s have a generalised K value. If K=5, it means, in the given dataset and we are splitting into 5 folds and running the Train and Test. During each run, one fold is considered for testing and the rest will be for training and moving on with iterations, the below pictorial representation would give you an idea of the flow of the fold-defined size.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/K-fold-cross-vaslidation3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/K-fold-cross-vaslidation3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/K-fold-cross-vaslidation3-1400.webp"/> <img src="/assets/img/K-fold-cross-vaslidation3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Life Cycle of K-Fold Cross-Validation. </div> <p>In which each data point is used, once in the hold-out set and K-1 in Training. So, during the full iteration at least once, one fold will be used for testing and the rest for training.</p> <p>In the above set, 5- Testing 20 Training. In each iteration, we will get an accuracy score and have to sum them and find the mean. Here we can understand how the data is spread in a way of consistency and will make a conclusion whether to for the production with this model (or) NOT.</p> <h2 id="model-selection-using-k-fold">Model Selection using K-Fold</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">digits</span> <span class="o">=</span> <span class="nf">load_digits</span><span class="p">()</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">,</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</code></pre></div></div> <h2 id="frequently-asked-questions">Frequently Asked Questions</h2> <h3 id="q1-what-is-k-fold-cross-validation-value">Q1. What is k-fold cross-validation value?</h3> <p>A. K-fold cross-validation is a technique used in machine learning and statistical modeling to evaluate the performance of a predictive model. It involves dividing the dataset into k subsets or folds of approximately equal size. The model is then trained and evaluated k times, each time using a different fold as the validation set and the remaining folds as the training set. The performance metrics obtained from each fold are averaged to provide a more robust estimate of the model’s generalization performance. Common values for k are 5 and 10, but other values can also be used depending on the dataset size and complexity.</p> <h3 id="q2-how-do-you-use-k-fold-cross-validation">Q2. How do you use K-fold cross validation?</h3> <p>A. K-fold cross-validation is used to assess the performance of a machine learning model and to estimate its generalization ability. Here are the steps to utilize K-fold cross-validation:</p> <ol> <li>Split the data: Divide your dataset into k equal-sized subsets (folds). Typically, k is chosen as 5 or 10, but you can adjust it based on your needs.</li> <li>Train and validate: Iterate over the k folds. In each iteration, use k-1 folds for training the model and the remaining fold for validation. Train your model on the training folds and evaluate its performance on the validation fold.</li> <li>Performance metrics: Calculate the performance metric(s) of interest (e.g., accuracy, precision, recall) for each fold. These metrics quantify how well the model generalizes to unseen data.</li> <li>Average the results: Average the performance metrics obtained from the k folds to obtain a more robust estimate of the model’s performance. This average value represents the overall performance of the model.</li> <li>Model selection and tuning: Based on the cross-validation results, you can compare different models or hyperparameter settings and select the one that performs the best on average across the folds.</li> <li>Final evaluation: After selecting the model or hyperparameters, you can retrain the model using the entire dataset and evaluate its performance on a separate test set to obtain a final performance estimation. K-fold cross-validation helps to mitigate the risk of overfitting and provides a more reliable assessment of how well the model is expected to perform on unseen data.</li> </ol> <h2 id="conclusion">Conclusion</h2> <p>Guys! so far, we have discussed various aspects of the K-Fold Cross Validation Technique and its importance in the Machine Learning model for production, parameter selection with a classical example. I trust this article would help you all to understand this topic better. If you ask me if we have any disadvantages of this, my answer would be Yes! That is nothing but slow in execution than straightforward training and test. In spite of this small drawback, K Fold cross-validation plays a critical role in the Machine Learning world.</p>]]></content><author><name></name></author><category term="PHD"/><category term="Code"/><summary type="html"><![CDATA[K-fold cross-validation is a technique for evaluating predictive models.]]></summary></entry><entry><title type="html">How to Write the Scope of the Study</title><link href="https://woffee.github.io/blog/2023/scope-of-study/" rel="alternate" type="text/html" title="How to Write the Scope of the Study"/><published>2023-06-12T13:56:00+00:00</published><updated>2023-06-12T13:56:00+00:00</updated><id>https://woffee.github.io/blog/2023/scope-of-study</id><content type="html" xml:base="https://woffee.github.io/blog/2023/scope-of-study/"><![CDATA[<p>Source: <a href="https://www.discoverphds.com/blog/scope-of-the-study">https://www.discoverphds.com/blog/scope-of-the-study</a></p> <p>The scope of the study is defined at the start of the research project before data collection begins. It is used by researchers to set the boundaries and limitations within which the study will be performed.</p> <h2 id="what-is-the-scope-of-the-study">What is the Scope of the Study?</h2> <p>The scope of the study refers to the boundaries within which your research project will be performed; this is sometimes also called the scope of research. To define the scope of the study is to define all aspects that will be considered in your research project. It is also just as important to make clear what aspects will not be covered; i.e. what is outside of the scope of the study.</p> <h2 id="why-is-the-scope-of-the-study-important">Why is the Scope of the Study Important?</h2> <p>The scope of the study is always considered and agreed upon in the early stages of the project, before any data collection or experimental work has started. This is important because it focuses the work of the proposed study down to what is practically achievable within a given timeframe.</p> <p>A well-defined research or study scope enables a researcher to give clarity to the study outcomes that are to be investigated. It makes clear why specific data points have been collected whilst others have been excluded.</p> <p>Without this, it is difficult to define an end point for a research project since no limits have been defined on the work that could take place. Similarly, it can also make the approach to answering a research question too open ended.</p> <h2 id="how-do-you-write-the-scope-of-the-study">How do you Write the Scope of the Study?</h2> <p>In order to write the scope of the study that you plan to perform, you must be clear on the research parameters that you will and won’t consider. These parameters usually consist of the sample size, the duration, inclusion and exclusion criteria, the methodology and any geographical or monetary constraints.</p> <p>Each of these parameters will have limits placed on them so that the study can practically be performed, and the results interpreted relative to the limitations that have been defined. These parameters will also help to shape the direction of each research question you consider.</p> <p>The term limitations’ is often used together with the scope of the study to describe the constraints of any parameters that are considered and also to clarify which parameters have not been considered at all. Make sure you get the balance right here between not making the scope too broad and unachievable, and it not being too restrictive, resulting in a lack of useful data.</p> <p>The sample size is a commonly used parameter in the definition of the research scope. For example, a research project involving human participants may define at the start of the study that 100 participants will be recruited. This number will be determined based on an understanding of the difficulty in recruiting participants to studies and an agreement of an acceptable period of time in which to recruit this number.</p> <p>Any results that are obtained by the research group can then be interpreted by others with the knowledge that the study was capped to 100 participants and an acceptance of this as a limitation of the study. In other words, it is acknowledged that recruiting 100 rather than 1,000 participants has limited the amount of data that could be collected, however this is an acceptable limitation due to the known difficulties in recruiting so many participants (e.g. the significant period of time it would take and the costs associated with this).</p> <h2 id="example-of-a-scope-of-the-study">Example of a Scope of the Study</h2> <p>The follow is a (hypothetical) example of the definition of the scope of the study, with the research question investigating <em>the impact of the COVID-19 pandemic on mental health</em>.</p> <p>Whilst the immediate negative health problems related to the COVID-19 pandemic have been well documented, the impact of the virus on the mental health (MH) of young adults (age 18-24 years) is poorly understood. The aim of this study is to report on MH changes in population group due to the pandemic.</p> <p>The scope of the study is limited to recruiting 100 volunteers between the ages of 18 and 24 who will be contacted using their university email accounts. This recruitment period will last for a maximum of 2 months and will end when either 100 volunteers have been recruited or 2 months have passed. Each volunteer to the study will be asked to complete a short questionnaire in order to evaluate any changes in their MH.</p> <p>From this example we can immediately see that the scope of the study has placed a constraint on the sample size to be used and/or the time frame for recruitment of volunteers. It has also introduced a limitation by only opening recruitment to people that have university emails; i.e. anyone that does not attend university will be excluded from this study.</p> <p>This may be an important factor when interpreting the results of this study; the comparison of MH during the pandemic between those that do and do not attend university, is therefore outside the scope of the study here. We are also told that the methodology used to assess any changes in MH are via a questionnaire. This is a clear definition of how the outcome measure will be investigated and any other methods are not within the scope of research and their exclusion may be a limitation of the study.</p> <h2 id="conclusion">Conclusion</h2> <p>The scope of the study is important to define as it enables a researcher to focus their research to within achievable parameters.</p>]]></content><author><name></name></author><category term="Blog"/><category term="PHD"/><summary type="html"><![CDATA[In this post you will learn exactly what the scope of the study means, why it is important in your research, how you would write one and finally you’ll be presented with an example scope of a study.]]></summary></entry><entry><title type="html">Show labels when hovering over a point</title><link href="https://woffee.github.io/blog/2023/Matplotlib-Show-labels-when-hovering-over-a-point/" rel="alternate" type="text/html" title="Show labels when hovering over a point"/><published>2023-01-13T13:56:00+00:00</published><updated>2023-01-13T13:56:00+00:00</updated><id>https://woffee.github.io/blog/2023/Matplotlib-Show-labels-when-hovering-over-a-point</id><content type="html" xml:base="https://woffee.github.io/blog/2023/Matplotlib-Show-labels-when-hovering-over-a-point/"><![CDATA[<p>Show labels when hovering over a point.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/matplotlib-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/matplotlib-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/matplotlib-1400.webp"/> <img src="/assets/img/matplotlib.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Show labels when hovering over a point. </div> <p>This code is modified based on <a href="https://stackoverflow.com/questions/7908636/possible-to-make-labels-appear-when-hovering-over-a-point-in-matplotlib">here</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">class</span> <span class="nc">My_show</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">names</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="n">self</span><span class="p">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">colors</span>

        <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">RdYlGn</span>

        <span class="n">self</span><span class="p">.</span><span class="n">fig</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sc</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">c</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">norm</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">annot</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="nf">annotate</span><span class="p">(</span><span class="sh">""</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="sh">"</span><span class="s">offset points</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">bbox</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="sh">"</span><span class="s">round</span><span class="sh">"</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">),</span>
                            <span class="n">arrowprops</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="sh">"</span><span class="s">-&gt;</span><span class="sh">"</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_annot</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">):</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">sc</span><span class="p">.</span><span class="nf">get_offsets</span><span class="p">()[</span><span class="n">ind</span><span class="p">[</span><span class="sh">"</span><span class="s">ind</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="n">xy</span> <span class="o">=</span> <span class="n">pos</span>
        <span class="c1"># text = "{}, {}".format(" ".join(list(map(str,ind["ind"]))),
</span>        <span class="c1">#                        " ".join([self.names[n] for n in ind["ind"]]))
</span>        <span class="n">text</span> <span class="o">=</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">names</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">[</span><span class="sh">"</span><span class="s">ind</span><span class="sh">"</span><span class="p">]])</span>

        <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">set_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">get_bbox_patch</span><span class="p">().</span><span class="nf">set_facecolor</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">cmap</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">c</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="sh">"</span><span class="s">ind</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]])))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">get_bbox_patch</span><span class="p">().</span><span class="nf">set_alpha</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">hover</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">event</span><span class="p">):</span>
        <span class="n">vis</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">get_visible</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">event</span><span class="p">.</span><span class="n">inaxes</span> <span class="o">==</span> <span class="n">self</span><span class="p">.</span><span class="n">ax</span><span class="p">:</span>
            <span class="n">cont</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">sc</span><span class="p">.</span><span class="nf">contains</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cont</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">update_annot</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">canvas</span><span class="p">.</span><span class="nf">draw_idle</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">vis</span><span class="p">:</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">annot</span><span class="p">.</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">canvas</span><span class="p">.</span><span class="nf">draw_idle</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">canvas</span><span class="p">.</span><span class="nf">mpl_connect</span><span class="p">(</span><span class="sh">"</span><span class="s">motion_notify_event</span><span class="sh">"</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hover</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="n">my</span> <span class="o">=</span> <span class="nc">My_show</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">colors</span><span class="p">)</span>
    <span class="n">my</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div>]]></content><author><name></name></author><category term="Blog"/><category term="Code"/><summary type="html"><![CDATA[Show labels when hovering over a point]]></summary></entry><entry><title type="html">DeepVD</title><link href="https://woffee.github.io/blog/2023/DeepVD/" rel="alternate" type="text/html" title="DeepVD"/><published>2023-01-13T13:56:00+00:00</published><updated>2023-01-13T13:56:00+00:00</updated><id>https://woffee.github.io/blog/2023/DeepVD</id><content type="html" xml:base="https://woffee.github.io/blog/2023/DeepVD/"><![CDATA[<p>The advances of machine learning (ML) including deep learning (DL) have enabled several approaches to implicitly learn vulnerable code patterns to automatically detect software vulnerabilities.</p> <h2 id="abstract">Abstract</h2> <p>A recent study showed that despite successes, the existing ML/DL-based vulnerability detection (VD) models are limited in the ability to distinguish between the two classes of vulnerability and benign code. We propose DeepVD, a graph-based neural network VD model that emphasizes on class-separation features between vulnerability and benign code. DeepVD leverages three types of class-separation features at different levels of abstraction: statement types (similar to Part-of-Speech tagging), Post-Dominator Tree (covering regular flows of execution), and Exception Flow Graph (covering the exception and error-handling flows). We conducted several experiments to evaluate DeepVD in a real-world vulnerability dataset of 303 projects with 13,130 vulnerable methods. Our results show that DeepVD relatively improves over the state-of-the-art ML/DL-based VD approaches 13%–29.6% in precision, 15.6%–28.9% in recall, and 16.4%–25.8% in F-score. Our ablation study confirms that our designed features and components help DeepVD achieve high class-separability for vulnerability and benign code. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>https://conf.researchr.org/details/icse-2023/icse-2023-technical-track/155/DeepVD-Toward-Class-Separation-Features-for-Neural-Network-Vulnerability-Detection <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="PHD"/><category term="DL"/><category term="Publications"/><summary type="html"><![CDATA[DeepVD - Toward Class-Separation Features for Neural Network Vulnerability Detection]]></summary></entry><entry><title type="html">QA4GIS</title><link href="https://woffee.github.io/blog/2021/QA4GIS/" rel="alternate" type="text/html" title="QA4GIS"/><published>2021-07-19T13:56:00+00:00</published><updated>2021-07-19T13:56:00+00:00</updated><id>https://woffee.github.io/blog/2021/QA4GIS</id><content type="html" xml:base="https://woffee.github.io/blog/2021/QA4GIS/"><![CDATA[<p>Community-based question answering websites have attracted more and more scholars and developers to discuss domain knowledge and software development. In this article, we focus on the GIS section of the Stack Exchange website and develop a novel approach, QA4GIS, a deep learning-based system for question answering tasks with a deep neural network (DNN) model to extract the representation of the query–API document pair. We use the LambdaMART model to rerank the candidate API documents. We begin with an empirical analysis of the questions and answers, demonstrating that API documents could answer 52.93% of the questions. Then we evaluate QA4GIS by comparing it with 10 other baselines. The experiment results show that QA4GIS can improve 21.39% on the MAP score and 22.34% on the MRR score compared with the best baseline SIF. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Wang, W., Li, Y., Wang, S., &amp; Ye, X. (2021). QA4GIS: A novel approach learning to answer GIS developer questions with API documentation. Transactions in GIS, 00, 1-26. http://doi.org/10.1111/tgis.12798 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="PHD"/><category term="DL"/><category term="NLP"/><category term="GIS"/><category term="Publications"/><summary type="html"><![CDATA[A novel approach learning to answer GIS developer questions with API documentation]]></summary></entry></feed>